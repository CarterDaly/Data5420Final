{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>SP500_Open</th>\n",
       "      <th>SP500_Close</th>\n",
       "      <th>Day_Before_Close</th>\n",
       "      <th>Two_Days_Later_Close</th>\n",
       "      <th>Week_Later_Close</th>\n",
       "      <th>SP500_MA_3</th>\n",
       "      <th>SP500_MA_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recession now... or stagflation forever</td>\n",
       "      <td>2024-09-13 16:45:00</td>\n",
       "      <td>5603.339844</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>5595.759766</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>5713.640137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mortgage rates are dropping, but homes are not...</td>\n",
       "      <td>2024-09-13 16:40:00</td>\n",
       "      <td>5603.339844</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>5595.759766</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>5713.640137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hospitality stocks out-innovate challenges as ...</td>\n",
       "      <td>2024-09-13 16:34:47</td>\n",
       "      <td>5603.339844</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>5595.759766</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>5713.640137</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ratings agency fitch says extended strike at b...</td>\n",
       "      <td>2024-09-13 16:30:33</td>\n",
       "      <td>5603.339844</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>5595.759766</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>5713.640137</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google parent company in bear territory, down ...</td>\n",
       "      <td>2024-09-13 16:28:47</td>\n",
       "      <td>5603.339844</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>5595.759766</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>5713.640137</td>\n",
       "      <td>5626.02002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title              pubDate  \\\n",
       "0            recession now... or stagflation forever  2024-09-13 16:45:00   \n",
       "1  mortgage rates are dropping, but homes are not...  2024-09-13 16:40:00   \n",
       "2  hospitality stocks out-innovate challenges as ...  2024-09-13 16:34:47   \n",
       "3  ratings agency fitch says extended strike at b...  2024-09-13 16:30:33   \n",
       "4  google parent company in bear territory, down ...  2024-09-13 16:28:47   \n",
       "\n",
       "    SP500_Open  SP500_Close  Day_Before_Close  Two_Days_Later_Close  \\\n",
       "0  5603.339844   5626.02002       5595.759766            5626.02002   \n",
       "1  5603.339844   5626.02002       5595.759766            5626.02002   \n",
       "2  5603.339844   5626.02002       5595.759766            5626.02002   \n",
       "3  5603.339844   5626.02002       5595.759766            5626.02002   \n",
       "4  5603.339844   5626.02002       5595.759766            5626.02002   \n",
       "\n",
       "   Week_Later_Close  SP500_MA_3  SP500_MA_7  \n",
       "0       5713.640137         NaN         NaN  \n",
       "1       5713.640137         NaN         NaN  \n",
       "2       5713.640137  5626.02002         NaN  \n",
       "3       5713.640137  5626.02002         NaN  \n",
       "4       5713.640137  5626.02002         NaN  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('articles_with_sp500.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert pubDate to datetime\n",
    "df['pubDate'] = pd.to_datetime(df['pubDate'])\n",
    "\n",
    "# Convert headlines to numerical representation using TF-IDF\n",
    "vectorizer = TfidfVectorizer(min_df=2, max_df=0.9)\n",
    "X_text = vectorizer.fit_transform(df['title'])\n",
    "\n",
    "# Extract the numerical features that will be the output targets\n",
    "numerical_features = df[['SP500_Open', 'SP500_Close', 'Day_Before_Close', 'Two_Days_Later_Close', 'Week_Later_Close', \n",
    "                         'SP500_MA_3', 'SP500_MA_7']].values\n",
    "\n",
    "# Define the target variables (numerical features)\n",
    "target = numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_text.toarray(), target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y_train_scaled = scaler.fit_transform(y_train)\n",
    "y_test_scaled = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MarketPredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MarketPredictionModel, self).__init__()\n",
    "        \n",
    "        # Define the 12 layers\n",
    "        self.fc1 = nn.Linear(input_dim, 8192)  # First layer\n",
    "        self.fc2 = nn.Linear(8192, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 4096)\n",
    "        self.fc4 = nn.Linear(4096, 4096)\n",
    "        self.fc5 = nn.Linear(4096, 2048)\n",
    "        self.fc6 = nn.Linear(2048, 1024)\n",
    "        self.fc7 = nn.Linear(1024, 512)\n",
    "        self.fc8 = nn.Linear(512, 256)\n",
    "        self.fc9 = nn.Linear(256, 128)\n",
    "        self.fc10 = nn.Linear(128, 64)\n",
    "        self.fc11 = nn.Linear(64, 32)\n",
    "        self.fc12 = nn.Linear(32, output_dim)  # Final output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply ReLU activation to each layer\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = torch.relu(self.fc7(x))\n",
    "        x = torch.relu(self.fc8(x))\n",
    "        x = torch.relu(self.fc9(x))\n",
    "        x = torch.relu(self.fc10(x))\n",
    "        x = torch.relu(self.fc11(x))\n",
    "        x = self.fc12(x)  # Output layer (no activation for regression)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "input_dim = X_train.shape[1]  # Number of features (TF-IDF features)\n",
    "output_dim = y_train_scaled.shape[1]  # Number of target variables (numerical features)\n",
    "model = MarketPredictionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/90], Loss: 1.0091\n",
      "Epoch [20/90], Loss: 1.0060\n",
      "Epoch [30/90], Loss: 1.0014\n",
      "Epoch [40/90], Loss: 0.9973\n",
      "Epoch [50/90], Loss: 0.9660\n",
      "Epoch [60/90], Loss: 0.7769\n",
      "Epoch [70/90], Loss: 0.6662\n",
      "Epoch [80/90], Loss: 0.6386\n",
      "Epoch [90/90], Loss: 0.6301\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "num_epochs = 90\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    outputs = model(X_train_tensor)  # Forward pass\n",
    "    loss = criterion(outputs, y_train_tensor)  # Compute the loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update the weights\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE (Overall): 11187.676657010223\n",
      "MSE for SP500_Open: 11234.079008303548\n",
      "MSE for SP500_Close: 10855.17092314485\n",
      "MSE for Day_Before_Close: 11212.116222051452\n",
      "MSE for Two_Days_Later_Close: 11116.872180562585\n",
      "MSE for Week_Later_Close: 11302.53296149022\n",
      "MSE for SP500_MA_3: 11424.655097327064\n",
      "MSE for SP500_MA_7: 11168.310206191838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get predictions from the model\n",
    "    predictions_scaled = model(X_test_tensor)\n",
    "    \n",
    "    # Convert predictions to numpy for inverse scaling\n",
    "    predictions_scaled_numpy = predictions_scaled.numpy()\n",
    "\n",
    "    # Inverse scale the predictions to the original scale (for all 7 features)\n",
    "    predictions_unscaled = scaler.inverse_transform(predictions_scaled_numpy)\n",
    "\n",
    "    # Calculate the overall Mean Squared Error (MSE)\n",
    "    mse_overall = mean_squared_error(y_test, predictions_unscaled)\n",
    "    print(f\"Test MSE (Overall): {mse_overall}\")\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE) for each feature\n",
    "    feature_names = ['SP500_Open', 'SP500_Close', 'Day_Before_Close', \n",
    "                     'Two_Days_Later_Close', 'Week_Later_Close', \n",
    "                     'SP500_MA_3', 'SP500_MA_7']\n",
    "\n",
    "    for feature_idx, feature_name in enumerate(feature_names):\n",
    "        mse_feature = mean_squared_error(y_test[:, feature_idx], predictions_unscaled[:, feature_idx])\n",
    "        print(f\"MSE for {feature_name}: {mse_feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      "    SP500_Open - Predicted: 5716.19677734375, Actual: 5641.68017578125\n",
      "    SP500_Close - Predicted: 5716.40234375, Actual: 5618.259765625\n",
      "    Day_Before_Close - Predicted: 5707.28125, Actual: 5634.580078125\n",
      "    Two_Days_Later_Close - Predicted: 5728.59765625, Actual: 5702.5498046875\n",
      "    Week_Later_Close - Predicted: 5762.2607421875, Actual: 5732.93017578125\n",
      "    SP500_MA_3 - Predicted: 5713.86181640625, Actual: 5618.259765625\n",
      "    SP500_MA_7 - Predicted: 5709.4013671875, Actual: 5618.259765625\n",
      "--------------------------------------------------\n",
      "Sample 1\n",
      "    SP500_Open - Predicted: 5816.47412109375, Actual: 5912.7900390625\n",
      "    SP500_Close - Predicted: 5842.4755859375, Actual: 5870.6201171875\n",
      "    Day_Before_Close - Predicted: 5824.21875, Actual: 5870.6201171875\n",
      "    Two_Days_Later_Close - Predicted: 5827.7783203125, Actual: 5916.97998046875\n",
      "    Week_Later_Close - Predicted: 5863.02734375, Actual: 5969.33984375\n",
      "    SP500_MA_3 - Predicted: 5821.95458984375, Actual: 5870.6201171875\n",
      "    SP500_MA_7 - Predicted: 5825.0400390625, Actual: 5870.6201171875\n",
      "--------------------------------------------------\n",
      "Sample 2\n",
      "    SP500_Open - Predicted: 5816.50146484375, Actual: 5912.7900390625\n",
      "    SP500_Close - Predicted: 5842.45166015625, Actual: 5870.6201171875\n",
      "    Day_Before_Close - Predicted: 5824.20166015625, Actual: 5870.6201171875\n",
      "    Two_Days_Later_Close - Predicted: 5827.775390625, Actual: 5916.97998046875\n",
      "    Week_Later_Close - Predicted: 5863.0537109375, Actual: 5969.33984375\n",
      "    SP500_MA_3 - Predicted: 5821.92626953125, Actual: 5870.6201171875\n",
      "    SP500_MA_7 - Predicted: 5825.04248046875, Actual: 5870.6201171875\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Optionally, print sample-wise predictions and actual values for each feature\n",
    "for i in range(3):\n",
    "    print(f\"Sample {i}\")\n",
    "    for feature_idx, feature_name in enumerate(feature_names):\n",
    "        print(f\"    {feature_name} - Predicted: {predictions_unscaled[i, feature_idx]}, Actual: {y_test[i, feature_idx]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 samples with the largest errors:\n",
      "Sample 1 (Index 561) - Max Error: 296.29\n",
      "    SP500_Open - Predicted: 5709.17529296875, Actual: 5976.759765625\n",
      "    SP500_Close - Predicted: 5707.5361328125, Actual: 5995.5400390625\n",
      "    Day_Before_Close - Predicted: 5699.24853515625, Actual: 5995.5400390625\n",
      "    Two_Days_Later_Close - Predicted: 5721.69482421875, Actual: 6001.35009765625\n",
      "    Week_Later_Close - Predicted: 5754.73779296875, Actual: 5870.6201171875\n",
      "    SP500_MA_3 - Predicted: 5706.5966796875, Actual: 5995.5400390625\n",
      "    SP500_MA_7 - Predicted: 5700.966796875, Actual: 5995.5400390625\n",
      "--------------------------------------------------\n",
      "Sample 2 (Index 592) - Max Error: 293.46\n",
      "    SP500_Open - Predicted: 5711.65380859375, Actual: 5976.759765625\n",
      "    SP500_Close - Predicted: 5710.666015625, Actual: 5995.5400390625\n",
      "    Day_Before_Close - Predicted: 5702.083984375, Actual: 5995.5400390625\n",
      "    Two_Days_Later_Close - Predicted: 5724.1318359375, Actual: 6001.35009765625\n",
      "    Week_Later_Close - Predicted: 5757.3935546875, Actual: 5870.6201171875\n",
      "    SP500_MA_3 - Predicted: 5709.16162109375, Actual: 5995.5400390625\n",
      "    SP500_MA_7 - Predicted: 5703.9443359375, Actual: 5995.5400390625\n",
      "--------------------------------------------------\n",
      "Sample 3 (Index 782) - Max Error: 266.35\n",
      "    SP500_Open - Predicted: 5725.92822265625, Actual: 5992.27978515625\n",
      "    SP500_Close - Predicted: 5728.6943359375, Actual: 5987.3701171875\n",
      "    Day_Before_Close - Predicted: 5718.4150390625, Actual: 5969.33984375\n",
      "    Two_Days_Later_Close - Predicted: 5738.16650390625, Actual: 5998.740234375\n",
      "    Week_Later_Close - Predicted: 5772.68994140625, Actual: 6032.3798828125\n",
      "    SP500_MA_3 - Predicted: 5723.93310546875, Actual: 5987.3701171875\n",
      "    SP500_MA_7 - Predicted: 5721.09375, Actual: 5987.3701171875\n",
      "--------------------------------------------------\n",
      "Sample 4 (Index 384) - Max Error: 265.78\n",
      "    SP500_Open - Predicted: 5695.1552734375, Actual: 5912.7900390625\n",
      "    SP500_Close - Predicted: 5689.9443359375, Actual: 5870.6201171875\n",
      "    Day_Before_Close - Predicted: 5683.38916015625, Actual: 5949.169921875\n",
      "    Two_Days_Later_Close - Predicted: 5708.189453125, Actual: 5870.6201171875\n",
      "    Week_Later_Close - Predicted: 5740.00732421875, Actual: 5948.7099609375\n",
      "    SP500_MA_3 - Predicted: 5692.20068359375, Actual: 5870.6201171875\n",
      "    SP500_MA_7 - Predicted: 5684.44873046875, Actual: 5870.6201171875\n",
      "--------------------------------------------------\n",
      "Sample 5 (Index 727) - Max Error: 257.12\n",
      "    SP500_Open - Predicted: 5752.724609375, Actual: 5944.35986328125\n",
      "    SP500_Close - Predicted: 5762.537109375, Actual: 5969.33984375\n",
      "    Day_Before_Close - Predicted: 5749.07177734375, Actual: 5969.33984375\n",
      "    Two_Days_Later_Close - Predicted: 5764.5126953125, Actual: 6021.6298828125\n",
      "    Week_Later_Close - Predicted: 5801.404296875, Actual: 6032.3798828125\n",
      "    SP500_MA_3 - Predicted: 5751.662109375, Actual: 5969.33984375\n",
      "    SP500_MA_7 - Predicted: 5753.28662109375, Actual: 5969.33984375\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the following variables:\n",
    "# predictions_unscaled (your inverse scaled predictions)\n",
    "# y_test (actual values)\n",
    "\n",
    "# Step 1: Calculate absolute errors for each feature\n",
    "abs_errors = np.abs(predictions_unscaled - y_test)\n",
    "\n",
    "# Step 2: Calculate the maximum absolute error for each sample (across all features)\n",
    "max_abs_errors = np.max(abs_errors, axis=1)\n",
    "\n",
    "# Step 3: Sort samples by the maximum absolute error\n",
    "sorted_indices = np.argsort(max_abs_errors)[::-1]  # Sort in descending order\n",
    "\n",
    "# Step 4: Display the top N samples with the largest errors\n",
    "top_n = 5  # Set the number of top samples you want to view\n",
    "print(f\"Top {top_n} samples with the largest errors:\")\n",
    "\n",
    "for i in range(top_n):\n",
    "    idx = sorted_indices[i]\n",
    "    print(f\"Sample {i+1} (Index {idx}) - Max Error: {max_abs_errors[idx]:.2f}\")\n",
    "    for feature_idx, feature_name in enumerate(['SP500_Open', 'SP500_Close', 'Day_Before_Close', \n",
    "                                                 'Two_Days_Later_Close', 'Week_Later_Close', \n",
    "                                                 'SP500_MA_3', 'SP500_MA_7']):\n",
    "        print(f\"    {feature_name} - Predicted: {predictions_unscaled[idx, feature_idx]}, Actual: {y_test[idx, feature_idx]}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textfinalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
